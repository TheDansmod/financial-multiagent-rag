r"""Split markdown files, get segment summaries, and populate vector db with the chunks.

1. First, split the markdown files by the markdown header to obtain segment documents.
   Obtain summaries for each segment using an LLM.
2. Then, split the segments sentence by sentence - using an LLM where needed.
3. Then, decontexualise each sentence by passing the sentence and some context (previous
   sentences) to an LLM. Each decontextualised sentence is now a chunk, as are all of
   the summaries.
4. Embed both, the sentences and the summaries into the vector database. Ensure that the
   summary is part of the metadata of each sentence.

Rough (TODO - delete later):
    1. Generate section summaries function - split md by header, get per section summary
       and store the summaries in a json file
    2. Decontexualise function - split each section by sentences, decontextualise each
       sentence and store the result in a json file
    3. Populate vector db function - embed both the decontextualised sentences and the
       summaries and populate a vector db with them

10 Jan 2026:
    19:00 - I checked with gemini and it seems to think doing sentence by sentence
    summaries is not a very good idea. This and other approaches are a little complex
    and I just want to create the database and move along. So, I am going to generate
    the embeddings by using the summaries and just do splits based on the number of
    characters with some overlap - after doing the markdown based splits (not based on
    newlines since I already have markdown section summaries).
    19:29 - For now, I will just have the section summaries as metadata
    20:05 - I am using collection name sec_10k_19_Jan, chunk size 512, overlap 128
"""

import logging
from pathlib import Path
from uuid import uuid4

from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
from langchain_text_splitters import (
    RecursiveCharacterTextSplitter,
)
from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams

from src.utils.utils import load_from_json_list_file

log = logging.getLogger(__name__)


def populate_vector_db(cfg):
    r"""Populate vector db with chunks using the json file with md splits and summaries.

    We will be iterating through the elements of the json file which contains the
    content and summary of the various markdown sections, split the content of each
    section using the recursive character splitter, add the existing metadata and the
    section summaries as the chunk metadata, and add these chunks to the Qdrant Vector
    database.

    The json file contains a list of elements. Each element corresponds to one section
    in the original markdown file (as generated by the MarkdownHeaderTextSplitter).
    Each element contains the keys `ticker` (like NVDA), `page_content` (actual text
    from the markdown file), `id` (a UUID4 string), `metadata` (a dictionary which
    contains the headers obtained from the MarkdownHeaderTextSplitter), `summary` (
    the summary for this section obtained from LLMs).
    """
    path = Path(cfg.pre_proc.header_splits_file_path)
    header_splits = load_from_json_list_file(path, fail_on_error=True)
    docs = []
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=cfg.vector_db.chunk_size,
        chunk_overlap=cfg.vector_db.chunk_overlap,
        separators=["\n\n", "\n", " ", ""],
    )
    for split in header_splits:
        chunks = splitter.split_text(split["page_content"])
        for chunk in chunks:
            metadata = split["metadata"] | {
                "type": "content",
                "section_summary": split["summary"],
                "ticker": split["ticker"],
            }
            docs.append(
                Document(page_content=chunk, metadata=metadata, id=str(uuid4()))
            )
    # add the documents to vector db
    embedding_model = cfg.vector_db.embedding_model
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
    client = QdrantClient(path=cfg.vector_db.qdrant_path)

    collection_name = cfg.vector_db.collection_name
    if not client.collection_exists(collection_name):
        log.info(f"Creating collection '{collection_name}'...")
        client.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(
                size=client.get_embedding_size(embedding_model),
                distance=Distance.COSINE,
            ),
        )
    else:
        log.info(
            f"Collection '{collection_name}' already exists. Appending documents..."
        )
    vector_store = QdrantVectorStore(
        client=client, collection_name=collection_name, embedding=embeddings
    )
    vector_store.add_documents(documents=docs)


if __name__ == "__main__":
    import hydra
    from dotenv import load_dotenv
    from omegaconf import DictConfig

    load_dotenv()
    with hydra.initialize(version_base=None, config_path="../../config/"):
        cfg: DictConfig = hydra.compose(
            config_name="config", overrides=[], return_hydra_config=True
        )
    hydra.core.utils.configure_log(cfg.hydra.job_logging, cfg.hydra.verbose)
    populate_vector_db(cfg)
