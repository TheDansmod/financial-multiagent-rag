defaults:
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

data:
  companies: [NVDA, AAPL, MSFT, AMZN, GOOGL, META, TSLA, WMT, JPM, NFLX]
  year: 2025
  data_folder: ${hydra.runtime.cwd}/data/edgar_tools_filings
  id_name: Vipin Kumar
  id_email: vipinkumar1993@gmail.com
  sec_api_key: ${oc.env:SEC_API_KEY}
  md_file_path: ${hydra.runtime.cwd}/data/sec_api/mineru/{ticker}/vlm/{ticker}.md
  content_list_file_path: ${hydra.runtime.cwd}/data/sec_api/mineru/{ticker}/vlm/{ticker}_content_list.json
  images_folder_path: ${hydra.runtime.cwd}/data/sec_api/mineru/{ticker}/vlm/images/
  table_descriptions_path: ${hydra.runtime.cwd}/misc/table_descriptions.json
  processed_md_file_path: ${hydra.runtime.cwd}/data/sec_api/processed_md_files/{ticker}.md
  header_splits_file_path: ${hydra.runtime.cwd}/misc/header_splits.json

vector_db:
  chunk_size: 1024
  chunk_overlap: 200
  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  collection_name: sec_10k
  qdrant_path: ${hydra.runtime.cwd}/qdrant_db

model:
  # name: llama3.1
  # name: deepseek-r1:8b
  # name: gemma-3-27b-it
  # name: mistral-large-latest
  _target_: utils.get_llm_provider
  name: gemma-3-27b-it
  temp: 1.0

agent_configs:
  supervisor_node: 
    system_prompt_template: |
      You are a financial analyst.
      Analyse the following user query and classify it: {user_query}.
      Provide a classification for the user query including query type (simple, comparison, or complex), and query companies which should indicate the companies that are involved in the query. If any company could be involved in the query, then don't list any company.
  planner_node:
    system_prompt_template: |
      You are a financial analyst.
      Analyse the following user query and generate sub-queries for it: {user_query}.
      Breakdown the provided user query into a list of simple sub-queries, which, when answered, would together answer the posed user query. Each simple sub-query should be related to exactly one company.
  retriever_node:
    num_closest_chunks: 10

prompts:
  table_description: |
    I have uploaded an image of a table. The table was taken from the SEC 10K filing for {company_name} Company. The context from the filing is:
    `{table_context}`
    
    Using the provided context and the table image, please derive (1) an overall summary of the table (2) a row-by-row exact description of the content of the table including any numerical figures and values. Sometimes, the context will not be relevant to the content of the table. In that case, please only refer to and use the context that is relevant to the table.
    The answer should have the following format:
    Table Summary: [The actual summary of the table in a few lines.] Row 1: [Text description of the contents of row 1 in full complete sentences.] Row 2: [Text description of the contents of row 2 in full complete sentences.] and so on for other rows.

    No other extraneous text should be present before or after the answer in the response. Also, no markdown should be used in the formatting of the answer
  chunking: |
    You are a precise chunking model. The purpose of the chunking is to generate an embedding for each chunk and put it in a vector database for retrieval augmented generation.
    You are provided with the following text segment: 
    {text_segment}

    The provided text segment is too large to be a single chunk. Please split the text segment into chunks which are substrings of the text segment so that, as far as possible, each chunk is self contained. Make as little modification to each chunk as possible to make it self contained. Ensure that as far as possible each chunk is only composed of substrings of the provided text segment.
    The output must strictly only contain a list of strings, where each string is a chunk and the length of the list is the number of chunks. Most of the references to "Our", "We", "The Company" will likely be to the company with the ticker {ticker}. Make replacements for these phrases as appropriate.

    For example, if a text segment is: "The causes of the cultural revolution are (1) mass unrest due to over-zealous policing; (2) draconian governmental policies that unjustly persecuted minorities; (3) the widespread suppression of free expression through burning books and closing television channels." then you can divide the text into three chunks as follows:
    ["One of the causes of the cultural revolution was mass unrest due to over-zealous policing.", "One of the causes of the cultural revolution was draconian governmental policies that unjustly persecuted minorities.", "One of the causes of the cultural revolution was the widespread suppression of free expression through burning books and closing television channels."]
  de_contexualization: |
    You are an expert editor specializing in document de-contextualization. I will provide you a main chunk of text, and a few more chunks that occured before the text for context. Your need to perform entity resolution, substitution, sentence de-contexualization, and reference resolution for all sentences in the main chunk. All chunks are derived from a SEC filing document of the company: {ticker}. Leave as much of the chunk untouched as possible. The goal is to have each sentence on its own make complete sense without requiring context sentences, as far as possible. If no de-contexualization is required on the provided main chunk, then provide the main chunk as response verbatim. Most of the references to "Our", "We", "The Company" will likely be to the company whose ticker is {ticker}. Make replacements for these phrases as appropriate.

    The main chunk:
    {main_chunk}

    The context:
    {chunk_context}

    The response should contain only the main chunk after de-contexualization has been completed on it. No extraneous text should be present in the response before or after the processed main chunk.
  header_section_summary: |
    You are an expert summarizer. I will provide a section of text below derived from SEC filings for the company whose ticker is {ticker}. The headings for the section is/are {section_headings}. Please provide a summary of what this section contains in at most 6 sentences. Ensure that the summary only uses the text I provide below. Do not inject any content into the summary that is not present in the text below. Ensure that the response contains no extraneous text before or after the summary. The response should contain only the summary. Most of the references to "Our", "We", "The Company" will likely be to the company whose ticker is {ticker}. Make replacements for these phrases as appropriate. If the section is small, use fewer than 6 sentences to summarise the section.

    The section of text is:
    {text_section}

hydra:
  verbose: false

temporary:
  amzn_md_path: ${hydra.runtime.cwd}/data/sec_api/mineru/amzn/auto/amzn.md
  amzn_content_list_path: ${hydra.runtime.cwd}/data/sec_api/mineru/amzn/auto/amzn_content_list.json
  urls_10k: [https://www.sec.gov/Archives/edgar/data/0001045810/000104581025000023/nvda-20250126.htm, https://www.sec.gov/Archives/edgar/data/0000320193/000032019325000079/aapl-20250927.htm, https://www.sec.gov/Archives/edgar/data/0000789019/000095017025100235/msft-20250630.htm, https://www.sec.gov/Archives/edgar/data/0001018724/000101872425000004/amzn-20241231.htm, https://www.sec.gov/Archives/edgar/data/0001652044/000165204425000014/goog-20241231.htm, https://www.sec.gov/Archives/edgar/data/0001326801/000132680125000017/meta-20241231.htm, https://www.sec.gov/Archives/edgar/data/0001318605/000162828025003063/tsla-20241231.htm, https://www.sec.gov/Archives/edgar/data/0000104169/000010416925000021/wmt-20250131.htm, https://www.sec.gov/Archives/edgar/data/0000019617/000001961725000270/jpm-20241231.htm, https://www.sec.gov/Archives/edgar/data/0001065280/000106528025000044/nflx-20241231.htm]
  amzn_cleaned_md_path: /mnt/windows/Users/lordh/Documents/LibraryOfBabel/Miscellany/Danish/linux_temp/temp_files/0422_amzn.md
  mistral_api_key: ${oc.env:MISTRAL_API_KEY}
  mineru_folders: [aapl, amzn, goog, jpm, meta, msft]
  image_path: ${hydra.runtime.cwd}/data/sec_api/mineru/aapl/vlm/images/0d2bad8fcdffadea5a88ab17d7cd58b8d7b06b3c31a5726d212cbbd5649a07be.jpg
  chunking_prompt: |
    You are a precise chunking model. The purpose of the chunking is to generate an embedding for each chunk and put it in a vector database for retrieval augmented generation.
    You are provided with the following text segment: 
    {text_segment}

    The provided text segment is too large to be a single chunk. Please split the text segment into chunks which are substrings of the text segment so that, as far as possible, each chunk is self contained. Make as little modification to each chunk as possible to make it self contained. Ensure that as far as possible each chunk is only composed of substrings of the provided text segment.
    The output must strictly only contain a list of strings, where each string is a chunk and the length of the list is the number of chunks. Most of the references to "Our", "We", "The Company" will likely be to the company with the ticker {ticker}. Make replacements for these phrases as appropriate.

    For example, if a text segment is: "The causes of the cultural revolution are (1) mass unrest due to over-zealous policing; (2) draconian governmental policies that unjustly persecuted minorities; (3) the widespread suppression of free expression through burning books and closing television channels." then you can divide the text into three chunks as follows:
    ["One of the causes of the cultural revolution was mass unrest due to over-zealous policing.", "One of the causes of the cultural revolution was draconian governmental policies that unjustly persecuted minorities.", "One of the causes of the cultural revolution was the widespread suppression of free expression through burning books and closing television channels."]
